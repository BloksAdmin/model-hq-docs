# Welcome to Model HQ Documentation

![Model HQ Documentation](https://raw.githubusercontent.com/BloksAdmin/model-hq-docs/master/public/og-image.png)

**Run Enterprise AI workflows securely, locally, and at scaleâ€”all in one platform.**

Model HQ is the fastest, easiest way to deploy and run **AI models directly on your PC or enterprise hardware**. With **no-code AI app creation, hardware-optimized performance, and built-in privacy safeguards**, Model HQ allows enterprises and individuals to build, deploy, and scale AI workflows seamlesslyâ€”**without relying on the cloud**.

ğŸ‘‰ [Explore Documentation](https://model-hq-docs.vercel.app/)

&nbsp;

## Key Features

* **Simplified AI Deployment** â€“ All-in-one platform for AI app creation and workflow deployment.
* **Hardware Optimization** â€“ Automatically optimized for **IntelÂ® AI PCs**, **QualcommÂ® Snapdragon PCs**, and enterprise servers.
* **100% Private & Secure** â€“ Models run **completely offline**, ensuring sensitive data never leaves your device.
* **Enterprise Control** â€“ Monitor, update, and scale across thousands of endpoints.
* **Built-in Safety Tools** â€“ Explainability, PII filtering, toxicity & bias monitoring, hallucination detection.
* **Seamless Deployment** â€“ Push AI workflows directly to end-user PCs with zero incremental per-token cost.

&nbsp;

## Model HQ Stats

* â¬‡ï¸ **10 seconds** â€“ Average time to download a single model
* â¬‡ï¸ **<30 minutes** â€“ Download **24 models** onto device
* ğŸ“¦ **100+ models** â€“ Optimized for AI PCs
* âš¡ **Up to 22B parameters** â€“ On Intel AI PCs
* ğŸ’¸ **\$0 per-token cost** â€“ When running models locally

&nbsp;

## Components

### **1. Developer Kit**

* No-code environment to **create AI apps, agents, and RAG chatbots**.
* Build document analysis workflows, knowledge retrieval systems, or domain-specific agents.
* Deploy apps directly to user PCs with one click.

### **2. User Client App**

* Lightweight app (<100 MB) to **run models locally**.
* Chat, deploy workflows, and run agents offline.
* Supports model inferencing up to **32B parameters** on modern AI PCs.

&nbsp;

## Processor-Optimized Models

Choose models that are fine-tuned for your device:

* **[Intel Supported Models](https://model-hq-docs.vercel.app/supported-models/intel)**

  * OpenVINO-optimized
  * GPU & NPU acceleration
  * 100+ optimized models for **Intel Core, Xeon, and Arc GPUs**

* **[Qualcomm Supported Models](https://model-hq-docs.vercel.app/supported-models/qualcomm)**

  * QNN-optimized
  * CPU & NPU acceleration
  * 80+ optimized models for **Snapdragon AI PCs and edge devices**

ğŸ‘‰ [Check System Requirements](https://model-hq-docs.vercel.app/system-configuration)

&nbsp;

## Learning Resources

* ğŸ¥ [Video Tutorials](https://model-hq-docs.vercel.app/video-tutorials) â€“ Step-by-step walkthroughs (AI Agents, Chat, Intel optimization).
* ğŸ“ [Blogs & Partner Solutions](https://model-hq-docs.vercel.app/blogs-and-partner-solutions) â€“ Technical insights and real-world use cases.
* ğŸ“– [Documentation](https://model-hq-docs.vercel.app/) â€“ Complete guide to configuration, chat, agents, bots, RAG workflows, tools, and more.

&nbsp;

## Documentation Overview

* [System Configuration](https://model-hq-docs.vercel.app/system-configuration) â€“ Configure your environment and system requirements

* [Getting Started](https://model-hq-docs.vercel.app/getting-started) â€“ Begin your Model HQ journey with setup guides

* Chat
  * [Chat Overview](https://model-hq-docs.vercel.app/chat) â€“ Overview of chat features
  * [Changing Chat Models](https://model-hq-docs.vercel.app/chat/changing-chat-model) â€“ Switch between different LLMs
  * [Error Handling](https://model-hq-docs.vercel.app/chat/error-handling) â€“ Handle chat errors gracefully

* Agents
  * [Agents Overview](https://model-hq-docs.vercel.app/agent) â€“ Build new AI agents
  * [Create New Agent](https://model-hq-docs.vercel.app/agent/create-new-agent) â€“ Create your own agent
  * [Agent Builder Menu](https://model-hq-docs.vercel.app/agent/agent-builder-menu) â€“ Understand the interface 
  * [Edit Agents](https://model-hq-docs.vercel.app/agent/edit-agent) â€“ Modify existing agents
  * [Batch Run](https://model-hq-docs.vercel.app/agent/multi-docs-agent) â€“ Process multiple documents simultaneously
  * [Using OpenAI or Anthropic Models](https://model-hq-docs.vercel.app/agent/openAI-and-anthropic) â€“ Building Agent workflows using OpenAI and Anthropic models

* [Bots](https://model-hq-docs.vercel.app/bots) - uild and customize your own bots

* RAG
  * [RAG Overview](https://model-hq-docs.vercel.app/rag/) â€“ Build and customize your own bots
  * [RAG Parsing](https://model-hq-docs.vercel.app/rag/rag-parsing) â€“ Turn your documents into a structured information
  * [Document Parsing Issues](https://model-hq-docs.vercel.app/rag/document-parsing-issues) â€“ Possible solutions for document parsing issues
  * [Error Handling](https://model-hq-docs.vercel.app/rag/error-handling) â€“ Handle chat errors gracefully

* [Models](https://model-hq-docs.vercel.app/models) â€“ Discover and manage AI models

* [Testing Models](https://model-hq-docs.vercel.app/testing-models) â€“ Test the model before using them

* Configs & Tools
  * [Tools](https://model-hq-docs.vercel.app/tools) â€“ Powerful utilities for managing your local setup and parsing documents
  * [Configs](https://model-hq-docs.vercel.app/configs) â€“ Provides a centralized interface for managing Model HQ's core settings

* [Share Your App](https://model-hq-docs.vercel.app/share-your-app) â€“ Share your Agents and Custom Chatbots with others

* [Shutdown](https://model-hq-docs.vercel.app/shutdown) â€“ Close the app safely as best practices and highly recommended

### Cookbooks (Step-by-Step Recipes)

* [Create Your Personalized Bot](https://model-hq-docs.vercel.app/cookbooks/personalized-bot)
* [Build Your Own RAG Bot](https://model-hq-docs.vercel.app/cookbooks/rag-bot)
* [No-Code Document Review Workflow](https://model-hq-docs.vercel.app/cookbooks/document-review-and-analysis-tool)
* [Hybrid Inferencing (AI PC + API Server)](https://model-hq-docs.vercel.app/cookbooks/hybrid-inferencing)
* [Photo to Email Automation](https://model-hq-docs.vercel.app/cookbooks/photo-to-email-automation)
* [Clinical Trial Screening Automation](https://model-hq-docs.vercel.app/cookbooks/clinical-trial-screening-autmation)

&nbsp;

## Supported Devices

* **Intel AI PCs** â€“ Arrow Lake, Meteor Lake, Lunar Lake, and most Intel laptops <5 years old
* **Qualcomm Snapdragon X AI PCs** â€“ Optimized for CPU + NPU execution
* **Enterprise Servers** â€“ Intel Xeon with OpenVINO optimizations
* **AMD Devices** â€“ Supported (CPU-only, limited acceleration)

ğŸ‘‰ Minimum recommended: **16 GB RAM**

&nbsp;

## Best Practices

* Switch **Power Mode** â†’ â€œBest Performanceâ€ before downloading models.
* Extend **sleep/hibernate timeouts** (â‰¥1 hour) to prevent interruptions.
* For best speed, uninstall **MS Copilot** (can reduce inferencing performance by 50%).

&nbsp;

## Support

Need help? Our team is here to guide you.

* [Visit LLMWare.ai](https://llmware.ai)
* [Visit Documentation](https://model-hq-docs.vercel.app/)
* [Contact Support](https://model-hq-docs.vercel.app/support)
* Email: **[support@aibloks.com](mailto:support@aibloks.com)**


&nbsp;

Want to give it a shot? Try [Model HQ Developer Version](https://llmware.ai/enterprise#developers-waitlist) today!!!
(90 days free trials. Terms and Conditions applied)