# Welcome to Model HQ Documentation

![Model HQ Documentation](https://raw.githubusercontent.com/BloksAdmin/model-hq-docs/master/public/og-image.png)

**Run Enterprise AI workflows securely, locally, and at scale—all in one platform.**

Model HQ is the fastest, easiest way to deploy and run **AI models directly on your PC or enterprise hardware**. With **no-code AI app creation, hardware-optimized performance, and built-in privacy safeguards**, Model HQ allows enterprises and individuals to build, deploy, and scale AI workflows seamlessly—**without relying on the cloud**.

👉 [Explore Documentation](https://model-hq-docs.vercel.app/)

&nbsp;

## Key Features

* **Simplified AI Deployment** – All-in-one platform for AI app creation and workflow deployment.
* **Hardware Optimization** – Automatically optimized for **Intel® AI PCs**, **Qualcomm® Snapdragon PCs**, and enterprise servers.
* **100% Private & Secure** – Models run **completely offline**, ensuring sensitive data never leaves your device.
* **Enterprise Control** – Monitor, update, and scale across thousands of endpoints.
* **Built-in Safety Tools** – Explainability, PII filtering, toxicity & bias monitoring, hallucination detection.
* **Seamless Deployment** – Push AI workflows directly to end-user PCs with zero incremental per-token cost.

&nbsp;

## Model HQ Stats

* ⬇️ **10 seconds** – Average time to download a single model
* ⬇️ **<30 minutes** – Download **24 models** onto device
* 📦 **100+ models** – Optimized for AI PCs
* ⚡ **Up to 22B parameters** – On Intel AI PCs
* 💸 **\$0 per-token cost** – When running models locally

&nbsp;

## Components

### **1. Developer Kit**

* No-code environment to **create AI apps, agents, and RAG chatbots**.
* Build document analysis workflows, knowledge retrieval systems, or domain-specific agents.
* Deploy apps directly to user PCs with one click.

### **2. User Client App**

* Lightweight app (<100 MB) to **run models locally**.
* Chat, deploy workflows, and run agents offline.
* Supports model inferencing up to **32B parameters** on modern AI PCs.

&nbsp;

## Processor-Optimized Models

Choose models that are fine-tuned for your device:

* **[Intel Supported Models](https://model-hq-docs.vercel.app/supported-models/intel)**

  * OpenVINO-optimized
  * GPU & NPU acceleration
  * 100+ optimized models for **Intel Core, Xeon, and Arc GPUs**

* **[Qualcomm Supported Models](https://model-hq-docs.vercel.app/supported-models/qualcomm)**

  * QNN-optimized
  * CPU & NPU acceleration
  * 80+ optimized models for **Snapdragon AI PCs and edge devices**

👉 [Check System Requirements](https://model-hq-docs.vercel.app/system-configuration)

&nbsp;

## Learning Resources

* 🎥 [Video Tutorials](https://model-hq-docs.vercel.app/video-tutorials) – Step-by-step walkthroughs (AI Agents, Chat, Intel optimization).
* 📝 [Blogs & Partner Solutions](https://model-hq-docs.vercel.app/blogs-and-partner-solutions) – Technical insights and real-world use cases.
* 📖 [Documentation](https://model-hq-docs.vercel.app/) – Complete guide to configuration, chat, agents, bots, RAG workflows, tools, and more.

&nbsp;

## Documentation Overview

* [System Configuration](https://model-hq-docs.vercel.app/system-configuration) – Configure your environment and system requirements

* [Getting Started](https://model-hq-docs.vercel.app/getting-started) – Begin your Model HQ journey with setup guides

* Chat
  * [Chat Overview](https://model-hq-docs.vercel.app/chat) – Overview of chat features
  * [Changing Chat Models](https://model-hq-docs.vercel.app/chat/changing-chat-model) – Switch between different LLMs
  * [Error Handling](https://model-hq-docs.vercel.app/chat/error-handling) – Handle chat errors gracefully

* Agents
  * [Agents Overview](https://model-hq-docs.vercel.app/agent) – Build new AI agents
  * [Create New Agent](https://model-hq-docs.vercel.app/agent/create-new-agent) – Create your own agent
  * [Agent Builder Menu](https://model-hq-docs.vercel.app/agent/agent-builder-menu) – Understand the interface 
  * [Edit Agents](https://model-hq-docs.vercel.app/agent/edit-agent) – Modify existing agents
  * [Batch Run](https://model-hq-docs.vercel.app/agent/multi-docs-agent) – Process multiple documents simultaneously
  * [Using OpenAI or Anthropic Models](https://model-hq-docs.vercel.app/agent/openAI-and-anthropic) – Building Agent workflows using OpenAI and Anthropic models

* [Bots](https://model-hq-docs.vercel.app/bots) - uild and customize your own bots

* RAG
  * [RAG Overview](https://model-hq-docs.vercel.app/rag/) – Build and customize your own bots
  * [RAG Parsing](https://model-hq-docs.vercel.app/rag/rag-parsing) – Turn your documents into a structured information
  * [Document Parsing Issues](https://model-hq-docs.vercel.app/rag/document-parsing-issues) – Possible solutions for document parsing issues
  * [Error Handling](https://model-hq-docs.vercel.app/rag/error-handling) – Handle chat errors gracefully

* [Models](https://model-hq-docs.vercel.app/models) – Discover and manage AI models

* [Testing Models](https://model-hq-docs.vercel.app/testing-models) – Test the model before using them

* Configs & Tools
  * [Tools](https://model-hq-docs.vercel.app/tools) – Powerful utilities for managing your local setup and parsing documents
  * [Configs](https://model-hq-docs.vercel.app/configs) – Provides a centralized interface for managing Model HQ's core settings

* [Share Your App](https://model-hq-docs.vercel.app/share-your-app) – Share your Agents and Custom Chatbots with others

* [Shutdown](https://model-hq-docs.vercel.app/shutdown) – Close the app safely as best practices and highly recommended

### Cookbooks (Step-by-Step Recipes)

* [Create Your Personalized Bot](https://model-hq-docs.vercel.app/cookbooks/personalized-bot)
* [Build Your Own RAG Bot](https://model-hq-docs.vercel.app/cookbooks/rag-bot)
* [No-Code Document Review Workflow](https://model-hq-docs.vercel.app/cookbooks/document-review-and-analysis-tool)
* [Hybrid Inferencing (AI PC + API Server)](https://model-hq-docs.vercel.app/cookbooks/hybrid-inferencing)
* [Photo to Email Automation](https://model-hq-docs.vercel.app/cookbooks/photo-to-email-automation)
* [Clinical Trial Screening Automation](https://model-hq-docs.vercel.app/cookbooks/clinical-trial-screening-autmation)

&nbsp;

## Supported Devices

* **Intel AI PCs** – Arrow Lake, Meteor Lake, Lunar Lake, and most Intel laptops <5 years old
* **Qualcomm Snapdragon X AI PCs** – Optimized for CPU + NPU execution
* **Enterprise Servers** – Intel Xeon with OpenVINO optimizations
* **AMD Devices** – Supported (CPU-only, limited acceleration)

👉 Minimum recommended: **16 GB RAM**

&nbsp;

## Best Practices

* Switch **Power Mode** → “Best Performance” before downloading models.
* Extend **sleep/hibernate timeouts** (≥1 hour) to prevent interruptions.
* For best speed, uninstall **MS Copilot** (can reduce inferencing performance by 50%).

&nbsp;

## Support

Need help? Our team is here to guide you.

* [Visit LLMWare.ai](https://llmware.ai)
* [Visit Documentation](https://model-hq-docs.vercel.app/)
* [Contact Support](https://model-hq-docs.vercel.app/support)
* Email: **[support@aibloks.com](mailto:support@aibloks.com)**


&nbsp;

Want to give it a shot? Try [Model HQ Developer Version](https://llmware.ai/enterprise#developers-waitlist) today!!!
(90 days free trials. Terms and Conditions applied)